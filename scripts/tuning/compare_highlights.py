#!/usr/bin/env python3
"""
ãƒã‚¤ãƒ©ã‚¤ãƒˆæ¤œå‡ºçµæœæ¯”è¼ƒãƒ„ãƒ¼ãƒ«

è¤‡æ•°ã®è¨­å®šã§ç”Ÿæˆã•ã‚ŒãŸãƒã‚¤ãƒ©ã‚¤ãƒˆæ¤œå‡ºçµæœã‚’æ¯”è¼ƒã—ã€
ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼èª¿æ•´ã®åŠ¹æœã‚’å¯è¦–åŒ–ã™ã‚‹ã€‚

Usage:
  python compare_highlights.py --results data/stage4_highlights/video_highlights_*.json
  python compare_highlights.py --video sumi-claude-code-04 --configs standard,aggressive,conservative
"""

import json
import time
from pathlib import Path
from typing import Dict, Any, List
import click


def load_highlight_result(file_path: Path) -> Dict[str, Any]:
    """
    ãƒã‚¤ãƒ©ã‚¤ãƒˆæ¤œå‡ºçµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
    
    Args:
        file_path: çµæœãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        
    Returns:
        Dict[str, Any]: ãƒã‚¤ãƒ©ã‚¤ãƒˆæ¤œå‡ºçµæœ
    """
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def compare_highlight_results(results: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    è¤‡æ•°ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆæ¤œå‡ºçµæœã‚’æ¯”è¼ƒã™ã‚‹
    
    Args:
        results: ãƒã‚¤ãƒ©ã‚¤ãƒˆæ¤œå‡ºçµæœã®ãƒªã‚¹ãƒˆ
        
    Returns:
        Dict[str, Any]: æ¯”è¼ƒçµæœ
    """
    comparison = {
        "summary": {},
        "details": [],
        "recommendations": []
    }
    
    # å„çµæœã®è©³ç´°åˆ†æ
    for result in results:
        config_name = result.get("config_name", "unknown")
        highlights = result.get("highlights", [])
        summary = result.get("summary", {})
        processing_time = result.get("processing_time", 0.0)
        
        detail = {
            "config_name": config_name,
            "highlight_count": len(highlights),
            "total_duration": summary.get("total_duration", 0.0),
            "average_score": summary.get("average_score", 0.0),
            "coverage_ratio": summary.get("coverage_ratio", 0.0),
            "processing_time": processing_time,
            "emotion_distribution": summary.get("emotion_distribution", {}),
            "score_distribution": summary.get("score_distribution", {}),
            "top_highlights": [
                {
                    "start": h.get("start", 0.0),
                    "end": h.get("end", 0.0),
                    "text": h.get("text", "")[:50] + "..." if len(h.get("text", "")) > 50 else h.get("text", ""),
                    "score": h.get("highlight_score", 0.0),
                    "emotion": h.get("dominant_emotion", "neutral")
                }
                for h in highlights[:3]  # ä¸Šä½3å€‹
            ]
        }
        
        comparison["details"].append(detail)
    
    # ã‚µãƒãƒªãƒ¼çµ±è¨ˆ
    if comparison["details"]:
        highlight_counts = [d["highlight_count"] for d in comparison["details"]]
        avg_scores = [d["average_score"] for d in comparison["details"]]
        processing_times = [d["processing_time"] for d in comparison["details"]]
        
        comparison["summary"] = {
            "total_configs": len(comparison["details"]),
            "highlight_count_range": {"min": min(highlight_counts), "max": max(highlight_counts)},
            "avg_score_range": {"min": min(avg_scores), "max": max(avg_scores)},
            "processing_time_range": {"min": min(processing_times), "max": max(processing_times)},
            "fastest_config": min(comparison["details"], key=lambda x: x["processing_time"])["config_name"],
            "most_highlights_config": max(comparison["details"], key=lambda x: x["highlight_count"])["config_name"],
            "highest_score_config": max(comparison["details"], key=lambda x: x["average_score"])["config_name"]
        }
    
    # æ¨å¥¨äº‹é …ç”Ÿæˆ
    comparison["recommendations"] = generate_recommendations(comparison["details"])
    
    return comparison


def generate_recommendations(details: List[Dict[str, Any]]) -> List[str]:
    """
    æ¯”è¼ƒçµæœã«åŸºã¥ã„ã¦æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆã™ã‚‹
    
    Args:
        details: æ¯”è¼ƒè©³ç´°ã®ãƒªã‚¹ãƒˆ
        
    Returns:
        List[str]: æ¨å¥¨äº‹é …ã®ãƒªã‚¹ãƒˆ
    """
    recommendations = []
    
    if not details:
        return ["æ¯”è¼ƒå¯¾è±¡ã®çµæœãŒã‚ã‚Šã¾ã›ã‚“"]
    
    # ãƒã‚¤ãƒ©ã‚¤ãƒˆæ•°ã®åˆ†æ
    highlight_counts = [d["highlight_count"] for d in details]
    max_count = max(highlight_counts)
    min_count = min(highlight_counts)
    
    if max_count == 0:
        recommendations.append("âš ï¸  ã™ã¹ã¦ã®è¨­å®šã§ãƒã‚¤ãƒ©ã‚¤ãƒˆãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚é–¾å€¤ã‚’ä¸‹ã’ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚")
    elif min_count == 0:
        recommendations.append("âš ï¸  ä¸€éƒ¨ã®è¨­å®šã§ãƒã‚¤ãƒ©ã‚¤ãƒˆãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ä¿å®ˆçš„ã™ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
    elif max_count > 20:
        recommendations.append("âš ï¸  ãƒã‚¤ãƒ©ã‚¤ãƒˆæ•°ãŒå¤šã™ãã‚‹è¨­å®šãŒã‚ã‚Šã¾ã™ã€‚é–¾å€¤ã‚’ä¸Šã’ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚")
    
    # ã‚¹ã‚³ã‚¢ã®åˆ†æ
    avg_scores = [d["average_score"] for d in details]
    if max(avg_scores) < 0.5:
        recommendations.append("ğŸ’¡ å¹³å‡ã‚¹ã‚³ã‚¢ãŒä½ã‚ã§ã™ã€‚ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é‡ã¿ã‚’ä¸Šã’ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚")
    
    # å‡¦ç†æ™‚é–“ã®åˆ†æ
    processing_times = [d["processing_time"] for d in details]
    if max(processing_times) > 1.0:
        recommendations.append("â±ï¸  å‡¦ç†æ™‚é–“ãŒé•·ã‚ã§ã™ã€‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼æœ€é©åŒ–ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚")
    
    # è¨­å®šåˆ¥ã®æ¨å¥¨
    best_config = max(details, key=lambda x: x["highlight_count"] if x["highlight_count"] > 0 else 0)
    if best_config["highlight_count"] > 0:
        recommendations.append(f"ğŸ¯ '{best_config['config_name']}' è¨­å®šãŒæœ€ã‚‚åŠ¹æœçš„ã§ã™ï¼ˆ{best_config['highlight_count']}å€‹æ¤œå‡ºï¼‰ã€‚")
    
    # ãƒãƒ©ãƒ³ã‚¹ã®è‰¯ã„è¨­å®šã®æ¨å¥¨
    balanced_configs = [d for d in details if 3 <= d["highlight_count"] <= 15 and d["average_score"] >= 0.3]
    if balanced_configs:
        best_balanced = max(balanced_configs, key=lambda x: x["average_score"])
        recommendations.append(f"âš–ï¸  ãƒãƒ©ãƒ³ã‚¹ã®è‰¯ã„è¨­å®š: '{best_balanced['config_name']}'")
    
    return recommendations


def format_comparison_report(comparison: Dict[str, Any]) -> str:
    """
    æ¯”è¼ƒçµæœã‚’ãƒ¬ãƒãƒ¼ãƒˆå½¢å¼ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã™ã‚‹
    
    Args:
        comparison: æ¯”è¼ƒçµæœ
        
    Returns:
        str: ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿ãƒ¬ãƒãƒ¼ãƒˆ
    """
    report = []
    report.append("=" * 80)
    report.append("ãƒã‚¤ãƒ©ã‚¤ãƒˆæ¤œå‡ºçµæœæ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆ")
    report.append("=" * 80)
    report.append("")
    
    # ã‚µãƒãƒªãƒ¼
    summary = comparison.get("summary", {})
    if summary:
        report.append("ğŸ“Š ã‚µãƒãƒªãƒ¼çµ±è¨ˆ")
        report.append("-" * 40)
        report.append(f"æ¯”è¼ƒè¨­å®šæ•°: {summary.get('total_configs', 0)}")
        
        highlight_range = summary.get("highlight_count_range", {})
        report.append(f"ãƒã‚¤ãƒ©ã‚¤ãƒˆæ•°ç¯„å›²: {highlight_range.get('min', 0)} - {highlight_range.get('max', 0)}å€‹")
        
        score_range = summary.get("avg_score_range", {})
        report.append(f"å¹³å‡ã‚¹ã‚³ã‚¢ç¯„å›²: {score_range.get('min', 0):.3f} - {score_range.get('max', 0):.3f}")
        
        time_range = summary.get("processing_time_range", {})
        report.append(f"å‡¦ç†æ™‚é–“ç¯„å›²: {time_range.get('min', 0):.3f} - {time_range.get('max', 0):.3f}ç§’")
        
        report.append("")
        report.append(f"ğŸ† æœ€é«˜æ€§èƒ½:")
        report.append(f"  æœ€é€Ÿè¨­å®š: {summary.get('fastest_config', 'N/A')}")
        report.append(f"  æœ€å¤šæ¤œå‡ºè¨­å®š: {summary.get('most_highlights_config', 'N/A')}")
        report.append(f"  æœ€é«˜ã‚¹ã‚³ã‚¢è¨­å®š: {summary.get('highest_score_config', 'N/A')}")
        report.append("")
    
    # è©³ç´°æ¯”è¼ƒ
    details = comparison.get("details", [])
    if details:
        report.append("ğŸ“‹ è©³ç´°æ¯”è¼ƒ")
        report.append("-" * 40)
        
        for detail in details:
            config_name = detail["config_name"]
            report.append(f"ğŸ”§ {config_name.upper()} è¨­å®š")
            report.append(f"  ãƒã‚¤ãƒ©ã‚¤ãƒˆæ•°: {detail['highlight_count']}å€‹")
            report.append(f"  ç·æ™‚é–“: {detail['total_duration']:.1f}ç§’")
            report.append(f"  å¹³å‡ã‚¹ã‚³ã‚¢: {detail['average_score']:.3f}")
            report.append(f"  å‡¦ç†æ™‚é–“: {detail['processing_time']:.3f}ç§’")
            
            # æ„Ÿæƒ…åˆ†å¸ƒ
            emotion_dist = detail.get("emotion_distribution", {})
            if emotion_dist:
                report.append(f"  æ„Ÿæƒ…åˆ†å¸ƒ: {', '.join([f'{e}: {c}å€‹' for e, c in emotion_dist.items()])}")
            
            # ãƒˆãƒƒãƒ—ãƒã‚¤ãƒ©ã‚¤ãƒˆ
            top_highlights = detail.get("top_highlights", [])
            if top_highlights:
                report.append(f"  ãƒˆãƒƒãƒ—ãƒã‚¤ãƒ©ã‚¤ãƒˆ:")
                for i, h in enumerate(top_highlights, 1):
                    report.append(f"    {i}. {h['start']:.1f}s-{h['end']:.1f}s (ã‚¹ã‚³ã‚¢:{h['score']:.3f}) {h['text']}")
            
            report.append("")
    
    # æ¨å¥¨äº‹é …
    recommendations = comparison.get("recommendations", [])
    if recommendations:
        report.append("ğŸ’¡ æ¨å¥¨äº‹é …")
        report.append("-" * 40)
        for rec in recommendations:
            report.append(f"  {rec}")
        report.append("")
    
    report.append("=" * 80)
    report.append(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆæ™‚åˆ»: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    report.append("=" * 80)
    
    return "\n".join(report)


@click.command()
@click.option('--results', '-r', multiple=True, type=click.Path(exists=True),
              help='æ¯”è¼ƒã™ã‚‹çµæœãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆè¤‡æ•°æŒ‡å®šå¯èƒ½ï¼‰')
@click.option('--video', '-v', default=None,
              help='å‹•ç”»IDï¼ˆè¨­å®šåã‹ã‚‰è‡ªå‹•æ¤œç´¢ï¼‰')
@click.option('--configs', '-c', default=None,
              help='è¨­å®šåã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§æŒ‡å®šï¼ˆä¾‹: standard,aggressive,conservativeï¼‰')
@click.option('--output', '-o', default=None,
              help='æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæŒ‡å®šã—ãªã„å ´åˆã¯æ¨™æº–å‡ºåŠ›ï¼‰')
@click.option('--format', 'output_format', default='text', type=click.Choice(['text', 'json']),
              help='å‡ºåŠ›å½¢å¼')
def main(results, video, configs, output, output_format):
    """
    ãƒã‚¤ãƒ©ã‚¤ãƒˆæ¤œå‡ºçµæœæ¯”è¼ƒãƒ„ãƒ¼ãƒ«
    """
    result_files = []
    
    # çµæœãƒ•ã‚¡ã‚¤ãƒ«ã®åé›†
    if results:
        result_files = [Path(r) for r in results]
    elif video and configs:
        # å‹•ç”»IDã¨è¨­å®šåã‹ã‚‰è‡ªå‹•æ¤œç´¢
        config_names = [c.strip() for c in configs.split(',')]
        highlights_dir = Path('data/stage4_highlights')
        
        for config_name in config_names:
            result_file = highlights_dir / f"{video}_highlights_{config_name}.json"
            if result_file.exists():
                result_files.append(result_file)
            else:
                click.echo(f"âš ï¸  çµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {result_file}")
    else:
        click.echo("âŒ --results ã¾ãŸã¯ --video ã¨ --configs ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
        return
    
    if not result_files:
        click.echo("âŒ æ¯”è¼ƒã™ã‚‹çµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    click.echo(f"ğŸ” {len(result_files)}å€‹ã®çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¯”è¼ƒä¸­...")
    
    # çµæœèª­ã¿è¾¼ã¿
    highlight_results = []
    for file_path in result_files:
        try:
            result = load_highlight_result(file_path)
            highlight_results.append(result)
            click.echo(f"  âœ… èª­ã¿è¾¼ã¿: {file_path.name}")
        except Exception as e:
            click.echo(f"  âŒ èª­ã¿è¾¼ã¿å¤±æ•—: {file_path.name} - {e}")
    
    if not highlight_results:
        click.echo("âŒ æœ‰åŠ¹ãªçµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # æ¯”è¼ƒå®Ÿè¡Œ
    comparison = compare_highlight_results(highlight_results)
    
    # å‡ºåŠ›
    if output_format == 'json':
        output_data = json.dumps(comparison, ensure_ascii=False, indent=2)
    else:
        output_data = format_comparison_report(comparison)
    
    if output:
        output_path = Path(output)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(output_data)
        click.echo(f"ğŸ“ æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜: {output_path}")
    else:
        click.echo(output_data)


if __name__ == '__main__':
    main()