#!/usr/bin/env python3
"""
ãƒãƒƒãƒãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼èª¿æ•´ãƒ„ãƒ¼ãƒ«

è¤‡æ•°ã®è¨­å®šã‚’ä¸€æ‹¬ã§å®Ÿè¡Œã—ã€çµæœã‚’æ¯”è¼ƒã™ã‚‹ã€‚
ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼èª¿æ•´ã®åŠ¹ç‡åŒ–ã‚’ç›®çš„ã¨ã™ã‚‹ã€‚

Usage:
  python batch_tune.py --video sumi-claude-code-04 --configs config/highlight_detection*.yaml
  python batch_tune.py --video sumi-claude-code-04 --preset all
"""

import json
import time
import subprocess
from pathlib import Path
from typing import Dict, Any, List
import click
from concurrent.futures import ThreadPoolExecutor, as_completed


def run_highlight_detection(
    emotions_file: str,
    config_file: str,
    output_dir: str = "data/stage4_highlights"
) -> Dict[str, Any]:
    """
    ãƒã‚¤ãƒ©ã‚¤ãƒˆæ¤œå‡ºãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè¡Œã™ã‚‹
    
    Args:
        emotions_file: æ„Ÿæƒ…åˆ†æçµæœãƒ•ã‚¡ã‚¤ãƒ«
        config_file: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
        output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        
    Returns:
        Dict[str, Any]: å®Ÿè¡Œçµæœ
    """
    config_path = Path(config_file)
    config_name = config_path.stem
    
    start_time = time.time()
    
    try:
        cmd = [
            "python", "process_highlights.py",
            "--input", emotions_file,
            "--output", output_dir,
            "--config", config_file
        ]
        
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=30  # 30ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
        )
        
        processing_time = time.time() - start_time
        
        if result.returncode == 0:
            # çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            video_id = Path(emotions_file).stem.replace('_text_emotions', '').replace('_audio_emotions', '')
            result_file = Path(output_dir) / f"{video_id}_highlights_{config_name}.json"
            
            if result_file.exists():
                with open(result_file, 'r', encoding='utf-8') as f:
                    highlight_result = json.load(f)
                
                return {
                    "config_name": config_name,
                    "config_file": str(config_file),
                    "success": True,
                    "processing_time": processing_time,
                    "highlight_count": len(highlight_result.get("highlights", [])),
                    "average_score": highlight_result.get("summary", {}).get("average_score", 0.0),
                    "total_duration": highlight_result.get("summary", {}).get("total_duration", 0.0),
                    "result_file": str(result_file),
                    "stdout": result.stdout,
                    "stderr": result.stderr
                }
            else:
                return {
                    "config_name": config_name,
                    "config_file": str(config_file),
                    "success": False,
                    "processing_time": processing_time,
                    "error": "çµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“",
                    "stdout": result.stdout,
                    "stderr": result.stderr
                }
        else:
            return {
                "config_name": config_name,
                "config_file": str(config_file),
                "success": False,
                "processing_time": processing_time,
                "error": f"ãƒ—ãƒ­ã‚»ã‚¹å®Ÿè¡Œå¤±æ•— (code: {result.returncode})",
                "stdout": result.stdout,
                "stderr": result.stderr
            }
            
    except subprocess.TimeoutExpired:
        return {
            "config_name": config_name,
            "config_file": str(config_file),
            "success": False,
            "processing_time": time.time() - start_time,
            "error": "ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ"
        }
    except Exception as e:
        return {
            "config_name": config_name,
            "config_file": str(config_file),
            "success": False,
            "processing_time": time.time() - start_time,
            "error": str(e)
        }


def get_preset_configs(preset: str) -> List[str]:
    """
    ãƒ—ãƒªã‚»ãƒƒãƒˆã«åŸºã¥ã„ã¦è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹
    
    Args:
        preset: ãƒ—ãƒªã‚»ãƒƒãƒˆå
        
    Returns:
        List[str]: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ
    """
    config_dir = Path("config")
    
    if preset == "all":
        pattern = "highlight_detection*.yaml"
    elif preset == "basic":
        pattern = "highlight_detection.yaml"
    elif preset == "comparison":
        return [
            "config/highlight_detection.yaml",
            "config/highlight_detection_aggressive.yaml",
            "config/highlight_detection_conservative.yaml"
        ]
    else:
        raise ValueError(f"ä¸æ˜ãªãƒ—ãƒªã‚»ãƒƒãƒˆ: {preset}")
    
    return [str(f) for f in config_dir.glob(pattern)]


def generate_batch_report(results: List[Dict[str, Any]], video_id: str) -> str:
    """
    ãƒãƒƒãƒå®Ÿè¡Œçµæœã®ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹
    
    Args:
        results: å®Ÿè¡Œçµæœã®ãƒªã‚¹ãƒˆ
        video_id: å‹•ç”»ID
        
    Returns:
        str: ãƒ¬ãƒãƒ¼ãƒˆæ–‡å­—åˆ—
    """
    report = []
    report.append("=" * 80)
    report.append(f"ãƒãƒƒãƒãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼èª¿æ•´ãƒ¬ãƒãƒ¼ãƒˆ - {video_id}")
    report.append("=" * 80)
    report.append("")
    
    # æˆåŠŸãƒ»å¤±æ•—çµ±è¨ˆ
    successful = [r for r in results if r.get("success", False)]
    failed = [r for r in results if not r.get("success", False)]
    
    report.append(f"ğŸ“Š å®Ÿè¡Œçµ±è¨ˆ")
    report.append(f"  ç·å®Ÿè¡Œæ•°: {len(results)}")
    report.append(f"  æˆåŠŸ: {len(successful)}")
    report.append(f"  å¤±æ•—: {len(failed)}")
    report.append("")
    
    # æˆåŠŸã—ãŸçµæœã®è©³ç´°
    if successful:
        report.append("âœ… æˆåŠŸã—ãŸè¨­å®š")
        report.append("-" * 60)
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é †ã§ã‚½ãƒ¼ãƒˆ
        successful.sort(key=lambda x: (-x.get("highlight_count", 0), x.get("processing_time", 999)))
        
        for result in successful:
            config_name = result["config_name"]
            highlight_count = result.get("highlight_count", 0)
            avg_score = result.get("average_score", 0.0)
            total_duration = result.get("total_duration", 0.0)
            processing_time = result.get("processing_time", 0.0)
            
            report.append(f"ğŸ”§ {config_name.upper()}")
            report.append(f"  ãƒã‚¤ãƒ©ã‚¤ãƒˆæ•°: {highlight_count}å€‹")
            report.append(f"  å¹³å‡ã‚¹ã‚³ã‚¢: {avg_score:.3f}")
            report.append(f"  ç·æ™‚é–“: {total_duration:.1f}ç§’")
            report.append(f"  å‡¦ç†æ™‚é–“: {processing_time:.3f}ç§’")
            report.append(f"  çµæœãƒ•ã‚¡ã‚¤ãƒ«: {result.get('result_file', 'N/A')}")
            report.append("")
    
    # å¤±æ•—ã—ãŸçµæœ
    if failed:
        report.append("âŒ å¤±æ•—ã—ãŸè¨­å®š")
        report.append("-" * 60)
        
        for result in failed:
            config_name = result["config_name"]
            error = result.get("error", "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼")
            processing_time = result.get("processing_time", 0.0)
            
            report.append(f"âš ï¸ {config_name.upper()}")
            report.append(f"  ã‚¨ãƒ©ãƒ¼: {error}")
            report.append(f"  å‡¦ç†æ™‚é–“: {processing_time:.3f}ç§’")
            if result.get("stderr"):
                report.append(f"  è©³ç´°: {result['stderr'][:100]}...")
            report.append("")
    
    # æ¨å¥¨äº‹é …
    if successful:
        report.append("ğŸ’¡ æ¨å¥¨äº‹é …")
        report.append("-" * 60)
        
        best_count = max(successful, key=lambda x: x.get("highlight_count", 0))
        best_score = max(successful, key=lambda x: x.get("average_score", 0.0))
        fastest = min(successful, key=lambda x: x.get("processing_time", 999))
        
        report.append(f"ğŸ¯ æœ€å¤šæ¤œå‡º: {best_count['config_name']} ({best_count.get('highlight_count', 0)}å€‹)")
        report.append(f"ğŸ† æœ€é«˜ã‚¹ã‚³ã‚¢: {best_score['config_name']} ({best_score.get('average_score', 0.0):.3f})")
        report.append(f"âš¡ æœ€é«˜é€Ÿ: {fastest['config_name']} ({fastest.get('processing_time', 0.0):.3f}ç§’)")
        report.append("")
        
        # ãƒãƒ©ãƒ³ã‚¹ã®è‰¯ã„è¨­å®šã‚’æ¨å¥¨
        balanced = [r for r in successful if 2 <= r.get("highlight_count", 0) <= 15 and r.get("average_score", 0.0) >= 0.5]
        if balanced:
            best_balanced = max(balanced, key=lambda x: x.get("average_score", 0.0))
            report.append(f"âš–ï¸  æ¨å¥¨è¨­å®š: {best_balanced['config_name']} (ãƒãƒ©ãƒ³ã‚¹é‡è¦–)")
        elif successful:
            report.append(f"âš–ï¸  æ¨å¥¨è¨­å®š: {best_count['config_name']} (æ¤œå‡ºæ•°é‡è¦–)")
        
        report.append("")
    
    # æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—
    report.append("ğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—")
    report.append("-" * 60)
    if successful:
        best_configs = [r['config_name'] for r in successful[:3]]
        report.append(f"1. ä¸Šä½è¨­å®šã§ã®è©³ç´°ç¢ºèª:")
        for config in best_configs:
            report.append(f"   python compare_highlights.py --video {video_id} --configs {config}")
        report.append("")
        report.append("2. æœ€é©è¨­å®šã§ã®ãƒ•ã‚¡ã‚¤ãƒŠãƒ«å®Ÿè¡Œ:")
        report.append(f"   python process_highlights.py --input data/stage3_emotions/{video_id}_text_emotions.json --config config/highlight_detection_{best_configs[0]}.yaml")
    else:
        report.append("1. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®è¦‹ç›´ã—")
        report.append("2. é–¾å€¤ã®èª¿æ•´")
        report.append("3. æ„Ÿæƒ…åˆ†æçµæœã®ç¢ºèª")
    
    report.append("")
    report.append("=" * 80)
    report.append(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆæ™‚åˆ»: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    report.append("=" * 80)
    
    return "\n".join(report)


@click.command()
@click.option('--video', '-v', required=True,
              help='å‹•ç”»ID')
@click.option('--configs', '-c', multiple=True, type=click.Path(),
              help='è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆè¤‡æ•°æŒ‡å®šå¯èƒ½ï¼‰')
@click.option('--preset', '-p', type=click.Choice(['all', 'basic', 'comparison']),
              help='ãƒ—ãƒªã‚»ãƒƒãƒˆè¨­å®š (all: å…¨è¨­å®š, basic: åŸºæœ¬è¨­å®šã®ã¿, comparison: æ¯”è¼ƒç”¨3è¨­å®š)')
@click.option('--output-dir', default='data/stage4_highlights',
              help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
@click.option('--parallel', '-j', default=3, type=int,
              help='ä¸¦åˆ—å®Ÿè¡Œæ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3ï¼‰')
@click.option('--report', '-r', default=None,
              help='ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæŒ‡å®šã—ãªã„å ´åˆã¯æ¨™æº–å‡ºåŠ›ï¼‰')
@click.option('--verbose', is_flag=True,
              help='è©³ç´°ãƒ­ã‚°å‡ºåŠ›')
def main(video, configs, preset, output_dir, parallel, report, verbose):
    """
    ãƒãƒƒãƒãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼èª¿æ•´ãƒ„ãƒ¼ãƒ«
    """
    click.echo(f"ğŸ¬ å‹•ç”»: {video}")
    
    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å–å¾—
    config_files = []
    
    if configs:
        config_files = list(configs)
    elif preset:
        config_files = get_preset_configs(preset)
    else:
        click.echo("âŒ --configs ã¾ãŸã¯ --preset ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
        return
    
    if not config_files:
        click.echo("âŒ å®Ÿè¡Œã™ã‚‹è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    click.echo(f"ğŸ”§ å®Ÿè¡Œè¨­å®šæ•°: {len(config_files)}")
    for config_file in config_files:
        click.echo(f"  - {config_file}")
    
    # æ„Ÿæƒ…åˆ†æãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
    emotions_file = f"data/stage3_emotions/{video}_text_emotions.json"
    if not Path(emotions_file).exists():
        click.echo(f"âŒ æ„Ÿæƒ…åˆ†æãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {emotions_file}")
        return
    
    click.echo(f"ğŸ“Š å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {emotions_file}")
    click.echo(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir}")
    click.echo(f"âš¡ ä¸¦åˆ—å®Ÿè¡Œæ•°: {parallel}")
    click.echo("")
    
    # ãƒãƒƒãƒå®Ÿè¡Œ
    start_time = time.time()
    results = []
    
    with ThreadPoolExecutor(max_workers=parallel) as executor:
        # å…¨ã‚¿ã‚¹ã‚¯ã‚’æŠ•å…¥
        future_to_config = {
            executor.submit(run_highlight_detection, emotions_file, config_file, output_dir): config_file
            for config_file in config_files
        }
        
        # å®Œäº†ã—ãŸã‚‚ã®ã‹ã‚‰çµæœã‚’å–å¾—
        for future in as_completed(future_to_config):
            config_file = future_to_config[future]
            try:
                result = future.result()
                results.append(result)
                
                config_name = result["config_name"]
                if result["success"]:
                    highlight_count = result.get("highlight_count", 0)
                    processing_time = result.get("processing_time", 0.0)
                    click.echo(f"âœ… {config_name}: {highlight_count}å€‹ ({processing_time:.3f}ç§’)")
                else:
                    error = result.get("error", "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼")
                    click.echo(f"âŒ {config_name}: {error}")
                    
                if verbose and result.get("stderr"):
                    click.echo(f"   è©³ç´°: {result['stderr']}")
                    
            except Exception as e:
                click.echo(f"âŒ {config_file}: ä¾‹å¤–ç™ºç”Ÿ - {e}")
                results.append({
                    "config_name": Path(config_file).stem,
                    "config_file": config_file,
                    "success": False,
                    "error": str(e),
                    "processing_time": 0.0
                })
    
    total_time = time.time() - start_time
    
    click.echo("")
    click.echo(f"ğŸ ãƒãƒƒãƒå®Ÿè¡Œå®Œäº† (ç·æ™‚é–“: {total_time:.2f}ç§’)")
    
    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report_content = generate_batch_report(results, video)
    
    if report:
        report_path = Path(report)
        report_path.parent.mkdir(parents=True, exist_ok=True)
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        click.echo(f"ğŸ“ ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜: {report_path}")
    else:
        click.echo("")
        click.echo(report_content)


if __name__ == '__main__':
    main()